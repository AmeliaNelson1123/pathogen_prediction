{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5d2693",
   "metadata": {},
   "source": [
    "# Listeria Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Introduction\n",
    "Exploratory Data Analysis was performed to see if any Data Engineering techniques can be effectively applied to enhance model results. \n",
    "\n",
    "This explores the data completeness, the distributions, the variance, and potential groupings or transformations. \n",
    "\n",
    "## This EDA explores \n",
    "- Missing data\n",
    "- Distributions of data\n",
    "- Log (and double log) transformations of the data distributions\n",
    "- Predictor column distributions\n",
    "- Summary statistics\n",
    "- Correlations\n",
    "- Feature Variance (further explored through PCA, cluster analysis, and Pairwise Scatterplots)\n",
    "- Cluster analysis\n",
    "- PCA analysis\n",
    "- Heatmaps\n",
    "- Pairwise Scatterplots\n",
    "\n",
    "## How to Run\n",
    "Here is a ipynb file that can be run in an IDE or Google Colab for model testing and results. Please input the file name you would like to test, and the predictor column.\n",
    "\n",
    "In this notebook, the exact same models that are provided on the competition, official git repo are used. The code is adapted to perform a grid search (search through a list of hyper parameters) to find the best model results.\n",
    "\n",
    "\n",
    "### NOTE:\n",
    "For the purposes of clarity, all of the outputs were cleared within this notebook due to large amount of graph outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2839cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dabe43",
   "metadata": {},
   "source": [
    "# Getting data\n",
    "Dividing numeric from numeric and non-numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da47618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd()\n",
    "if ROOT.name == \"preparation\":\n",
    "    ROOT = ROOT.parent\n",
    "DATA_PATH = ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63508d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "listeria_metadata = pd.read_csv(DATA_PATH / 'ListeriaSoil_Metadata.csv')\n",
    "print(listeria_metadata.head())\n",
    "\n",
    "listeria_data = pd.read_csv(DATA_PATH / 'ListeriaSoil_clean.csv')\n",
    "print(\"data is \", listeria_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd115b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling out only numeric\n",
    "listeria_numeric_data = listeria_data.select_dtypes(include='number')\n",
    "\n",
    "assert len(listeria_data) == len(listeria_numeric_data)\n",
    "\n",
    "print(\"col in old: \", len(listeria_data.columns), \"  col in new: \", len(listeria_numeric_data.columns), \"  length of both is: \", len(listeria_data))\n",
    "print(\"got all number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226d846",
   "metadata": {},
   "source": [
    "# Checks for completeness\n",
    "Checking if % add up to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f580e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if wetland, barren, forest, ... add up to 100\n",
    "# land coverage cols\n",
    "land_cov_cols = [\n",
    "    \"Open water (%)\",\n",
    "    \"Developed open space (< 20% Impervious Cover) (%)\",\n",
    "    \"Developed open space (> 20% Impervious Cover) (%)\",\n",
    "    \"Barren (%)\",\n",
    "    \"Forest (%)\",\n",
    "    \"Shrubland (%)\",\n",
    "    \"Grassland (%)\",\n",
    "    \"Cropland (%)\",\n",
    "    \"Pasture (%)\",\n",
    "    \"Wetland (%)\"\n",
    "]\n",
    "\n",
    "listeria_numeric_data[\"percent_check\"] = (listeria_numeric_data[land_cov_cols].sum(axis=1))\n",
    "\n",
    "# asserting everything adds up to 100\n",
    "assert np.all(np.isclose(listeria_numeric_data[\"percent_check\"], 100, atol=1e-9))\n",
    "\n",
    "print(listeria_numeric_data['percent_check'])\n",
    "\n",
    "listeria_numeric_data = listeria_numeric_data.drop(columns=\"percent_check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a3daf",
   "metadata": {},
   "source": [
    "# Distributions of Data VS Logged Distributions of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting columns that are normal or similar to normal (could do skewed, but most cols are skewed)\n",
    "normal_cols = [\"Latitude\", \"Longitude\", \"pH\", \"Max temperature (℃ )\",\"Min temperature (℃ )\", \"Molybdenum (mg/Kg)\", \"Wind speed (m/s)\"]\n",
    "\n",
    "# getting all cols that are skewed, but likely wont work with a log transform\n",
    "arithmatic_skew_cols = [\"Precipitation (mm)\", \"Number of Listeria isolates obtained\"]\n",
    "\n",
    "# getting skewed cols\n",
    "excluding_cols = set(normal_cols) | set(arithmatic_skew_cols)\n",
    "skewed_cols = [col for col in listeria_numeric_data.columns if col not in excluding_cols]\n",
    "print(skewed_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c00cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(skewed_cols))\n",
    "\n",
    "for col in skewed_cols:\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(listeria_numeric_data[col])\n",
    "    plt.title(f'Original Data: {col}')\n",
    "\n",
    "    logged_data = None\n",
    "    try: \n",
    "        logged_data = np.log(listeria_numeric_data[col])\n",
    "        # plotting\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(logged_data)\n",
    "        plt.title(f'Log Transform: {col}')\n",
    "    except:\n",
    "        logged_data = np.log1p(listeria_numeric_data[col])\n",
    "        # plotting\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(logged_data)\n",
    "        plt.title(f'Log1p Transform: {col}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bba1b4",
   "metadata": {},
   "source": [
    "### Analyzing and storing reasoning for whether or not to keep the log distribution versions or the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c56b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual entry of columns for log distribution based on histograms above\n",
    "\n",
    "# manually entering all of ones not to use because list is shorter\n",
    "transformed_not_enough = {\n",
    "    \"Zinc (mg/Kg)\": \"likely needs a second log transformation\",\n",
    "    \"Elevation (m)\": \"mostly just flipped the distribution skew\",\n",
    "    \"Sodium (mg/Kg)\": \"still skewed, but less so\",\n",
    "    \"Copper (mg/Kg)\": \"most values are 0, only <10 outliers\",\n",
    "    \"Wetland (%)\": \"0 heavy, and the rest is a really flat normal\",\n",
    "    \"Open water (%)\": \"heavy 0, and rest is almost uniform/steep then slow log\",\n",
    "    \"Developed open space (> 20% Impervious Cover) (%)\": \"heavy 0, rest is almost uniform\",\n",
    "    \"Barren (%)\": \"0 heavy with a few outliers\",\n",
    "    \"Forest (%)\": \"almost makes outliers, steep 0, then steep increase\",\n",
    "    \"Cropland (%)\": \"heavy 0, the rest almost normal\",\n",
    "    \"Pasture (%)\": \"still very 0 heavy, and almost a increasing pattern after 0\",\n",
    "}\n",
    "\n",
    "# notes on which of the bad we should still try with a log transform\n",
    "transform_bad_but_helpful = [\"Elevation (m)\", \"Sodium (mg/Kg)\", \"Open water (%)\", \"Developed open space (> 20% Impervious Cover) (%)\", \"Wetland (%)\", \"Cropland (%)\"]\n",
    "\n",
    "# noting which need to be double transformed with log\n",
    "double_transform = \"Zinc (mg/Kg)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da083d4",
   "metadata": {},
   "source": [
    "### Checking double log transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting to see if double transform worked\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(listeria_numeric_data[double_transform])\n",
    "plt.title(f'Original Data: {double_transform}')\n",
    "\n",
    "logged_data = None\n",
    "try: \n",
    "    logged_data = np.log(np.log(listeria_numeric_data[double_transform]))\n",
    "    # plotting\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(logged_data)\n",
    "    plt.title(f'Double Log Transform: {double_transform}')\n",
    "except:\n",
    "    # filling in all negative values with 0 instead of actual (because neg values are biologically impossible)\n",
    "    cleaned_col = [row_val if row_val > 0 else 1e-9 for row_val in listeria_numeric_data[double_transform]]\n",
    "    logged_data = np.log(np.log(cleaned_col))\n",
    "    # drop non finite for graphing purposes:\n",
    "    logged_data = logged_data.clip(1e-6) \n",
    "    logged_data = logged_data[np.isfinite(logged_data)]\n",
    "    if np.any(logged_data is np.inf):\n",
    "        print(\"still problem\")\n",
    "    # plotting\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(logged_data)\n",
    "    plt.title(f'Double Log Transform: {double_transform}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ff016",
   "metadata": {},
   "source": [
    "### quick checks to make sure the correct columns are being transformed or left as the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to transform = (not the ones in the bad list) + (the ones in the bad but still helpful list)\n",
    "to_transform = (set(skewed_cols) - set(transformed_not_enough.keys())) | set(transform_bad_but_helpful)\n",
    "assert \"Calcium (mg/Kg)\" in to_transform\n",
    "assert \"Elevation (m)\" in to_transform\n",
    "assert \"Pasture (%)\" not in to_transform\n",
    "\n",
    "# adding a log version to every one in the list above\n",
    "for col in to_transform:\n",
    "    print(col)\n",
    "    listeria_numeric_data[f\"log of {col}\"] = np.log(listeria_numeric_data[col])\n",
    "\n",
    "# dropping all non-log versions\n",
    "listeria_numeric_data = listeria_numeric_data.drop(columns=to_transform)\n",
    "assert \"Calcium (mg/Kg)\" not in listeria_numeric_data.columns\n",
    "assert \"Elevation (m)\" not in listeria_numeric_data.columns\n",
    "assert \"Pasture (%)\" in listeria_numeric_data.columns\n",
    "\n",
    "\n",
    "# completing the double log transform\n",
    "listeria_numeric_data[f\"double log of {double_transform}\"] = np.log(np.log(listeria_numeric_data[double_transform]))\n",
    "\n",
    "# dropping double log transform data\n",
    "listeria_numeric_data = listeria_numeric_data.drop(columns=double_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08a018",
   "metadata": {},
   "source": [
    "# Prediction Columns Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(listeria_numeric_data[\"Number of Listeria isolates obtained\"])\n",
    "plt.title(\"Number of Listeria Isolates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot for all listeria values vs only >0 vs binary (presense absense)\n",
    "# gettomg only above 0\n",
    "above_zero_only = listeria_data['Number of Listeria isolates obtained'][listeria_data['Number of Listeria isolates obtained'] > 0]\n",
    "print(above_zero_only)\n",
    "# getting only binary result\n",
    "listeria_numeric_data['binary_listeria_presense'] = [row_val if row_val == 0 else 1 for row_val in listeria_numeric_data['Number of Listeria isolates obtained']]\n",
    "\n",
    "plt.boxplot([listeria_data['Number of Listeria isolates obtained'], above_zero_only, listeria_numeric_data['binary_listeria_presense']], labels=['All values', '>0 only', 'binary presense absense'])\n",
    "\n",
    "\n",
    "# plotting info\n",
    "plt.title('All of the Listeria Isolates VS only >0')\n",
    "plt.ylabel('Number of Listeria Isolates')\n",
    "plt.xlabel('All vs >0')\n",
    "plt.show()\n",
    "\n",
    "# NOTE: it is okay that there are only circles, this is because \n",
    "# most of the data ended up being 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7de19a",
   "metadata": {},
   "source": [
    "# Summary Stats, mean median and mode of all the numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a555bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all mean, median, mode, min, and max from each numeric column\n",
    "summary_stats = pd.DataFrame({\n",
    "    \"mean\":   listeria_numeric_data.mean(),\n",
    "    \"median\": listeria_numeric_data.median(),\n",
    "    \"mode\":   listeria_numeric_data.mode().iloc[0], # NOTE: this only takes one of the modes if there are multiple\n",
    "    \"min\":    listeria_numeric_data.min(),\n",
    "    \"max\":    listeria_numeric_data.max(),\n",
    "})\n",
    "\n",
    "print(summary_stats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f40b00",
   "metadata": {},
   "source": [
    "# Correlations between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cdd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all variables\n",
    "corr_matrix = listeria_numeric_data.corr()\n",
    "\n",
    "# building heatmap\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=False, # remove the numbers above the heat value\n",
    "    cmap='coolwarm', # color pallate\n",
    "    cbar_kws={'shrink': .5} # adjusting color bar size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8abf44",
   "metadata": {},
   "source": [
    "### Defining groups of data that are more likely to be correlated + predictor Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38897a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new catagories of variables\n",
    "\n",
    "weather_variables = [\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"log of Elevation (m)\",\n",
    "    \"log of Moisture\",\n",
    "    \"Precipitation (mm)\",\n",
    "    \"Max temperature (℃ )\",\n",
    "    \"Min temperature (℃ )\",\n",
    "    \"Wind speed (m/s)\",\n",
    "    \"Number of Listeria isolates obtained\",\n",
    "    \"binary_listeria_presense\"\n",
    "]\n",
    "\n",
    "soil_variables = [\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"log of Total nitrogen (%)\",\n",
    "    \"log of Total carbon (%)\",\n",
    "    \"pH\",\n",
    "    \"log of Organic matter (%)\",\n",
    "    \"log of Aluminum (mg/Kg)\",\n",
    "    \"log of Calcium (mg/Kg)\",\n",
    "    \"Copper (mg/Kg)\",\n",
    "    \"log of Iron (mg/Kg)\",\n",
    "    \"log of Potassium (mg/Kg)\",\n",
    "    \"log of Magnesium (mg/Kg)\",\n",
    "    \"log of Manganese (mg/Kg)\",\n",
    "    \"Molybdenum (mg/Kg)\",\n",
    "    \"log of Sodium (mg/Kg)\",\n",
    "    \"log of Phosphorus (mg/Kg)\",\n",
    "    \"log of Sulfur (mg/Kg)\",\n",
    "    \"double log of Zinc (mg/Kg)\",\n",
    "    \"Number of Listeria isolates obtained\",\n",
    "    \"binary_listeria_presense\"\n",
    "]\n",
    "\n",
    "land_cover_variables = [\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"log of Elevation (m)\",\n",
    "    \"log of Open water (%)\",\n",
    "    \"log of Developed open space (< 20% Impervious Cover) (%)\",\n",
    "    \"log of Developed open space (> 20% Impervious Cover) (%)\",\n",
    "    \"Barren (%)\",\n",
    "    \"Forest (%)\",\n",
    "    \"log of Shrubland (%)\",\n",
    "    \"log of Grassland (%)\",\n",
    "    \"log of Cropland (%)\",\n",
    "    \"Pasture (%)\",\n",
    "    \"log of Wetland (%)\",\n",
    "    \"Number of Listeria isolates obtained\",\n",
    "    \"binary_listeria_presense\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f241712",
   "metadata": {},
   "source": [
    "### Running correlations between grouped-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just weather varriables\n",
    "corr_matrix = listeria_numeric_data[weather_variables].corr()\n",
    "\n",
    "# building heatmap\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True, # add the numbers above the heat value\n",
    "    cmap='coolwarm', # color pallate\n",
    "    fmt='.2f', # all correlations to 2 decimal places\n",
    "    linewidths=.5, # add lines between cells\n",
    "    square=True, # cells -> square\n",
    "    cbar_kws={'shrink': .5} # adjusting color bar size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23850645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just landcover variables\n",
    "corr_matrix = listeria_numeric_data[land_cover_variables].corr()\n",
    "\n",
    "# building heatmap\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True, # add the numbers above the heat value\n",
    "    cmap='coolwarm', # color pallate\n",
    "    fmt='.2f', # all correlations to 2 decimal places\n",
    "    linewidths=.5, # add lines between cells\n",
    "    square=True, # cells -> square\n",
    "    cbar_kws={'shrink': .5} # adjusting color bar size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just soil variables\n",
    "corr_matrix = listeria_numeric_data[soil_variables].corr()\n",
    "\n",
    "# building heatmap\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True, # add the numbers above the heat value\n",
    "    cmap='coolwarm', # color pallate\n",
    "    fmt='.1f', # all correlations to 2 decimal places\n",
    "    # linewidths=.5, # add lines between cells\n",
    "    square=True, # cells -> square\n",
    "    cbar_kws={'shrink': .5} # adjusting color bar size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf065f",
   "metadata": {},
   "source": [
    "# Creating a Scaled/Normalized copy of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# getting rid of the logged cols with inf\n",
    "only_finite_numeric = [col for col in listeria_numeric_data.columns if np.all(np.isfinite(listeria_numeric_data[col]))]\n",
    "\n",
    "print(\"num cols: \", len(only_finite_numeric), \" rows: \", len(only_finite_numeric))\n",
    "print(listeria_numeric_data[only_finite_numeric].head())\n",
    "# only want numeric columns\n",
    "data_to_fit = listeria_numeric_data[only_finite_numeric]\n",
    "# drop predictor variales\n",
    "data_to_fit = data_to_fit.drop(columns=['Number of Listeria isolates obtained', 'binary_listeria_presense'])\n",
    "scaled_listeria_num_data = scaler.fit_transform(data_to_fit)\n",
    "print(scaled_listeria_num_data[:5, :5])\n",
    "print(\"SHAPE: \", scaled_listeria_num_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba67de",
   "metadata": {},
   "source": [
    "# Feature Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_variance = listeria_numeric_data.var().sort_values(ascending=False)\n",
    "print(\"without scaled version\")\n",
    "print(feature_variance.head(10))\n",
    "\n",
    "scaled_feature_variance = np.sort(scaled_listeria_num_data.var(axis=0))\n",
    "print(\"scaled version\")\n",
    "print(\"this should all be 1 due to the scalar: \", scaled_feature_variance[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e009a32",
   "metadata": {},
   "source": [
    "# PCA analysis for variance (with and without scaling)\n",
    "Continuation of feature variance and feature importance (especially important for later cluster analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with scaling\n",
    "scaled_pca_fun = PCA()\n",
    "scaled_pca_data = scaled_pca_fun.fit_transform(scaled_listeria_num_data)\n",
    "\n",
    "# getting the cummulative sum (cum sum) of the variance to see how many PCA components we need and, in general, how much variation\n",
    "explained_var = np.cumsum(scaled_pca_fun.explained_variance_ratio_)\n",
    "\n",
    "# making graph easier to look at\n",
    "plt.plot(explained_var, marker='o')\n",
    "plt.axhline(0.8, linestyle='--', color='gray')\n",
    "# labeling axis and title\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('Scaled PCA cumulative explained variance')\n",
    "# displaying\n",
    "plt.show()\n",
    "\n",
    "print(only_finite_numeric)\n",
    "col_names = [col for col in only_finite_numeric if (col != \"Number of Listeria isolates obtained\" and col != \"binary_listeria_presense\")]\n",
    "# getting which variables drove the variance in the pca function\n",
    "loadings = pd.DataFrame(\n",
    "    scaled_pca_fun.components_.T,\n",
    "    index=col_names, # using listeria data instead of the scaled bc the scaled is a np array, and should align with the original\n",
    "    columns=[f\"PC{i+1}\" for i in range(scaled_pca_fun.n_components_)]\n",
    ")\n",
    "\n",
    "loadings[['PC1', 'PC2']].sort_values('PC1', key=np.abs, ascending=False).head(10)\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "pca_fun = PCA()\n",
    "pca_data = pca_fun.fit_transform(data_to_fit) # data to fit doesnt have the binary listeria or no. listeria isolates col\n",
    "\n",
    "# getting the cummulative sum (cum sum) of the variance to see how many PCA components we need and, in general, how much variation\n",
    "explained_var = np.cumsum(pca_fun.explained_variance_ratio_)\n",
    "\n",
    "# making graph easier to look at\n",
    "plt.plot(explained_var, marker='o')\n",
    "plt.axhline(0.8, linestyle='--', color='gray')\n",
    "# labeling axis and title\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('PCA cumulative explained variance')\n",
    "# displaying\n",
    "plt.show()\n",
    "\n",
    "# getting which variables drove the variance in the pca function\n",
    "loadings = pd.DataFrame(\n",
    "    pca_fun.components_.T,\n",
    "    index=col_names,\n",
    "    columns=[f\"PC{i+1}\" for i in range(pca_fun.n_components_)]\n",
    ")\n",
    "\n",
    "loadings[['PC1', 'PC2']].sort_values('PC1', key=np.abs, ascending=False).head(10)\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6182128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visuallizing the loadings\n",
    "# loadings is your DataFrame with index=feature names, columns=PC1, PC2, ...\n",
    "\n",
    "def plot_top_loadings(loadings, pc=\"PC1\", top_n=15):\n",
    "    s = loadings[pc].sort_values(key=np.abs, ascending=False).head(top_n)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.barh(s.index[::-1], s.values[::-1])\n",
    "    plt.xlabel(\"Loading (signed)\")\n",
    "    plt.title(f\"Top {top_n} loadings for {pc} on original data\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_top_loadings(loadings, \"PC1\", top_n=15)\n",
    "plot_top_loadings(loadings, \"PC2\", top_n=15)\n",
    "plot_top_loadings(loadings, \"PC3\", top_n=15)\n",
    "plot_top_loadings(loadings, \"PC4\", top_n=15)\n",
    "plot_top_loadings(loadings, \"PC5\", top_n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304de37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PCS = 5\n",
    "top_features = (\n",
    "    loadings[[f\"PC{i+1}\" for i in range(N_PCS)]]\n",
    "    .abs()\n",
    "    .max(axis=1)\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    "    .index\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(loadings.loc[top_features, [f\"PC{i+1}\" for i in range(N_PCS)]], aspect=\"auto\")\n",
    "plt.yticks(range(len(top_features)), top_features)\n",
    "plt.xticks(range(N_PCS), [f\"PC{i+1}\" for i in range(N_PCS)])\n",
    "plt.colorbar(label=\"Loading value\")\n",
    "plt.title(\"Loadings heatmap on original data (top 20 features across first 5 PCs)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4dd4c",
   "metadata": {},
   "source": [
    "# Cluster (testing with and without standard scaling bc clusters are distance based and the outlier skew could throw off the data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256d7b2",
   "metadata": {},
   "source": [
    "## KNN clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without standard scaling\n",
    "\n",
    "# setting starting variables\n",
    "speed = [] # inertia, this is one of the things we care about for clusters\n",
    "K = range(2, 100) # how many clusters testing over\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
    "    km.fit(data_to_fit)\n",
    "    speed.append(km.inertia_)\n",
    "\n",
    "# displaying plot\n",
    "plt.plot(K, speed, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow plot on original data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e58321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling\n",
    "\n",
    "# setting starting variables\n",
    "speed = [] # inertia, this is one of the things we care about for clusters\n",
    "K = range(2, 150) # how many clusters testing over\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
    "    km.fit(scaled_listeria_num_data)\n",
    "    speed.append(km.inertia_)\n",
    "\n",
    "# displaying plot\n",
    "plt.plot(K, speed, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow plot on scaled data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e99f5c",
   "metadata": {},
   "source": [
    "## Heirerarchical clustering because there seems to be more needed on cluster strucuture here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with scaled data\n",
    "\n",
    "k_range = range(2, 150)\n",
    "sil_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    model = AgglomerativeClustering(n_clusters=k, linkage=\"ward\")\n",
    "    labels = model.fit_predict(scaled_listeria_num_data)\n",
    "    sil_scores.append(silhouette_score(scaled_listeria_num_data, labels))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(k_range, sil_scores, marker='o')\n",
    "plt.xlabel(\"Number of clusters (k)\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.title(\"Hierarchical clustering on scaled data: silhouette vs k\")\n",
    "plt.show()\n",
    "\n",
    "# NOTE, none of these values unless approaching k = 1/2 or all of original data is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "k_range = range(2, 11)\n",
    "sil_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    model = AgglomerativeClustering(n_clusters=k, linkage=\"ward\")\n",
    "    labels = model.fit_predict(data_to_fit)\n",
    "    sil_scores.append(silhouette_score(listeria_data, labels))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(k_range, sil_scores, marker='o')\n",
    "plt.xlabel(\"Number of clusters (k)\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.title(\"Hierarchical clustering on original data: silhouette vs k\")\n",
    "plt.show()\n",
    "\n",
    "# note, supprisingly, 2 clusters actually performed okay, and was close to a 1, which means points were very well seperated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c315fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "Z = linkage(listeria_numeric_data[only_finite_numeric], method=\"ward\")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "dendrogram(Z, truncate_mode=\"level\", p=6)\n",
    "plt.title(\"Hierarchical dendrogram (Ward, truncated) on original data\")\n",
    "plt.xlabel(\"Samples / merged clusters\")\n",
    "plt.ylabel(\"Merge distance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5827dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled data\n",
    "Z = linkage(scaled_listeria_num_data, method=\"ward\")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "dendrogram(Z, truncate_mode=\"level\", p=6)\n",
    "plt.title(\"Hierarchical dendrogram (Ward, truncated) on scaled data\")\n",
    "plt.xlabel(\"Samples / merged clusters\")\n",
    "plt.ylabel(\"Merge distance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843cc48",
   "metadata": {},
   "source": [
    "## Observing how the PCA data fits with the best fit cluster derrived from the elbow curve\n",
    "- if the clusters are overlapping in pca data, probably less meaningful clustering, or weak structure.\n",
    "- try applying on regular data as well (with no pca reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb23cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled data\n",
    "\n",
    "# getting labels for most reasonable fit\n",
    "k = 6  # example\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
    "\n",
    "labels = kmeans.fit_predict(scaled_listeria_num_data)\n",
    "scaled_kmeans_fitter = kmeans.fit(scaled_listeria_num_data)\n",
    "\n",
    "listeria_numeric_data['scaled_cluster_kmeans'] = labels\n",
    "\n",
    "\n",
    "# saving the kmeans so that we can use for the website\n",
    "joblib.dump(scaled_kmeans_fitter, ROOT / \"website\" / \"backend\" / \"models\" / \"scaled_kmeans_fitter.joblib\")\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(scaled_pca_data[:,0], scaled_pca_data[:,1], c=labels, cmap='tab10', s=20)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('K-means clusters in PCA space on scaled data')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a967cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "# getting labels for most reasonable fit\n",
    "k = 6  # example\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
    "data_to_fit = listeria_numeric_data[only_finite_numeric]\n",
    "data_to_fit = data_to_fit.drop(columns=['Number of Listeria isolates obtained', 'binary_listeria_presense'])\n",
    "labels = kmeans.fit_predict(data_to_fit)\n",
    "kmeans_fitter = kmeans.fit(data_to_fit)\n",
    "print(len(listeria_numeric_data[only_finite_numeric].columns))\n",
    "listeria_numeric_data['cluster_kmeans'] = labels\n",
    "\n",
    "# saving the kmeans so that we can use for the website\n",
    "joblib.dump(kmeans_fitter,  ROOT / \"website\" / \"backend\" / \"models\" / \"kmeans_fitter.joblib\")\n",
    "\n",
    "# displaying clustered pca data on the first two components\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=labels, cmap='tab10', s=20)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('K-means clusters in PCA space on original data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking on non-scaled data with heirerarchical clustering\n",
    "pca = PCA(n_components=2)\n",
    "data_to_fit = listeria_numeric_data[only_finite_numeric]\n",
    "data_to_fit = data_to_fit.drop(columns=['Number of Listeria isolates obtained', 'binary_listeria_presense'])\n",
    "X_pca = pca.fit_transform(data_to_fit)\n",
    "\n",
    "labels = AgglomerativeClustering(n_clusters=3, linkage=\"ward\").fit_predict(listeria_numeric_data[only_finite_numeric])\n",
    "\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels, s=20)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Hierarchical clustering in PCA space on original data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking on non-scaled data with heirerarchical clustering\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(scaled_listeria_num_data)\n",
    "\n",
    "labels = AgglomerativeClustering(n_clusters=3, linkage=\"ward\").fit_predict(scaled_listeria_num_data)\n",
    "\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels, s=20)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Hierarchical clustering in PCA space on scaled data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a349ff",
   "metadata": {},
   "source": [
    "## GMM like cllustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b94b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on scaled data\n",
    "\n",
    "n_range = range(1, 15)\n",
    "bics = []\n",
    "\n",
    "for n in n_range:\n",
    "    gmm = GaussianMixture(\n",
    "        n_components=n,\n",
    "        covariance_type=\"full\",\n",
    "        random_state=42,\n",
    "        n_init=5\n",
    "    )\n",
    "    gmm.fit(scaled_listeria_num_data)\n",
    "    bics.append(gmm.bic(scaled_listeria_num_data))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(n_range, bics, marker='o')\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"BIC (lower is better)\")\n",
    "plt.title(\"GMM model selection via BIC\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "\n",
    "n_range = range(1, 11)\n",
    "bics = []\n",
    "\n",
    "for n in n_range:\n",
    "    gmm = GaussianMixture(\n",
    "        n_components=n,\n",
    "        covariance_type=\"full\",\n",
    "        random_state=42,\n",
    "        n_init=5\n",
    "    )\n",
    "    gmm.fit(data_to_fit)\n",
    "    bics.append(gmm.bic(data_to_fit))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(n_range, bics, marker='o')\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"BIC (lower is better)\")\n",
    "plt.title(\"GMM model selection via BIC on original data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1925c",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster profile\n",
    "# standardized features\n",
    "X = listeria_numeric_data.copy()\n",
    "Z = (X - X.mean()) / X.std(ddof=0)\n",
    "dfz = Z.copy()\n",
    "dfz[\"cluster\"] = listeria_numeric_data[\"cluster_kmeans\"]\n",
    "\n",
    "cluster_means = dfz.groupby(\"cluster\").mean()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(cluster_means, aspect=\"auto\")\n",
    "plt.colorbar(label=\"Mean z-score\")\n",
    "plt.xticks(range(cluster_means.shape[1]), cluster_means.columns, rotation=90, fontsize=7)\n",
    "plt.yticks(range(cluster_means.shape[0]), cluster_means.index)\n",
    "plt.title(\"Cluster feature profiles (mean z-score)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b0c7a",
   "metadata": {},
   "source": [
    "# Parwise scatter plots for land cover variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864298d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting which variables to do\n",
    "top_vars = (\n",
    "    loadings[[\"PC1\", \"PC2\"]]\n",
    "    .abs() # want neg and pos\n",
    "    .max(axis=1) # picking which ones to pull from and how to decide\n",
    "    .sort_values(ascending=False)\n",
    "    .head(6) # grabbing top 6 most influential variables\n",
    "    .index\n",
    ")\n",
    "\n",
    "print(top_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a parwise scatter plot\n",
    "pd.plotting.scatter_matrix(\n",
    "    listeria_numeric_data[top_vars],\n",
    "    diagonal='kde',\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "# plotting \n",
    "plt.suptitle(\"pairwise scatter: top PCA variables\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colloring scater plot by the cluster\n",
    "pd.plotting.scatter_matrix(\n",
    "    listeria_numeric_data[top_vars],\n",
    "    diagonal='kde',\n",
    "    alpha=0.5,\n",
    "    c=listeria_numeric_data['cluster_kmeans'],\n",
    "    cmap='tab10'\n",
    ")\n",
    "\n",
    "# plotting \n",
    "plt.suptitle(\"pairwise scatter: top PCA variables with cluster\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5912f",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data with cluster and log info\n",
    "listeria_numeric_data.to_csv(\"ListeriaSoil_clean_log.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
